{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Meat_Quality_Assessment_TL_Test_Documentation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNzq53S0JiLD0Qly9ElgmcQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AriesAnon/i-SenseCNN/blob/main/Meat_Quality_Assessment_TL_Test_Documentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Documentation for Transfer Learning using the Meat Quality Assessment from Kaggle***\n",
        "[link for the dataset](https://www.kaggle.com/crowww/meat-quality-assessment-based-on-deep-learning)\n",
        "\n",
        "[link for the youtube tutorial for TL](https://www.youtube.com/watch?v=sTVgH-R_Q5o&t=274s&ab_channel=CSbySahilSharma)\n",
        "\n",
        "Code below from: [github](https://github.com/sahil301290/Deep-Learning/blob/master/Lab%20Codes/07.%20Transfer%20Learning/Lab_7_Transfer_Learning.ipynb)\n",
        "\n",
        "\n",
        "# **Conclusion: The dataset might not be good or the optimization of the neural network.**\n",
        "\n",
        "**Advice: Try a different dataset with multiple classes instead of binary to simulate the final dataset. Last test would be the dataset with the three different kinds of meat. Fine tune that dataset and imitate the code and if possible add more into the dataset different kinds of pictures of the different cuts of specific meat.**\n",
        "\n",
        "\n",
        "# ***Epochs: 100***"
      ],
      "metadata": {
        "id": "fSGtpCDVnN2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from os import getcwd"
      ],
      "metadata": {
        "id": "B_Fq4W9YpCCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CX7WYbmFznWt",
        "outputId": "faa6b32b-eed0-43dc-c687-266efdc9974f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHwaPKQYzrBA",
        "outputId": "33a1fca6-a6dc-4a90-fb7c-35265abb9819"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Add the following arguments in the `pre_trained_model.load_weights` to prevent the error:**\n",
        "\n",
        "\n",
        "```\n",
        "# pre_trained_model.load_weights(local_weights_file, by_name=True)\n",
        "```\n",
        "Note to self: I do not know what this does except for the fact that it prevents the error where the weights does not match.\n"
      ],
      "metadata": {
        "id": "hdHi-zML3LNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_inception = f\"{getcwd()}/../content/drive/MyDrive/CNNRelatedFolders/TransferLearningModels/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = path_inception\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150,150,3),\n",
        "                               include_top  = False,\n",
        "                               weights      = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file, by_name=True)  # by_name=True argument is added to avoid conflict in weights\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "      layer.trainable = False\n",
        "\n",
        "# Print the model summary\n",
        "pre_trained_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fD3EvMszuFL",
        "outputId": "ac0853f7-56f6-4ba6-b92f-1deb824144d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 74, 74, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 74, 74, 32)  96          ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 74, 74, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 72, 72, 32)   9216        ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 72, 72, 32)  96          ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 72, 72, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 72, 72, 64)   18432       ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 72, 72, 64)  192         ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 72, 72, 64)   0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 35, 35, 64)   0           ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 35, 35, 80)   5120        ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 35, 35, 80)  240         ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 35, 35, 80)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 33, 33, 192)  138240      ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 33, 33, 192)  576        ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 33, 33, 192)  0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0          ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 16, 16, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 16, 16, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 16, 16, 96)   55296       ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 16, 16, 48)  144         ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 16, 16, 96)  288         ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 16, 16, 48)   0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 16, 16, 96)   0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 16, 16, 192)  0          ['max_pooling2d_1[0][0]']        \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 16, 16, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 16, 16, 64)   76800       ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 16, 16, 32)   6144        ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 16, 16, 96)  288         ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 16, 16, 32)  96          ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 16, 16, 32)   0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " mixed0 (Concatenate)           (None, 16, 16, 256)  0           ['activation_5[0][0]',           \n",
            "                                                                  'activation_7[0][0]',           \n",
            "                                                                  'activation_10[0][0]',          \n",
            "                                                                  'activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 16, 16, 64)  192         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 16, 16, 48)   12288       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 16, 16, 48)  144         ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 16, 16, 96)  288         ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 16, 16, 48)   0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (AveragePo  (None, 16, 16, 256)  0          ['mixed0[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 16, 16, 64)   76800       ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 16, 16, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 16, 16, 64)  192         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 16, 16, 64)  192         ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 16, 16, 96)  288         ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 16, 16, 64)  192         ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " mixed1 (Concatenate)           (None, 16, 16, 288)  0           ['activation_12[0][0]',          \n",
            "                                                                  'activation_14[0][0]',          \n",
            "                                                                  'activation_17[0][0]',          \n",
            "                                                                  'activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 16, 16, 64)  192         ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 16, 16, 48)   13824       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 16, 16, 48)  144         ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 16, 16, 96)  288         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 16, 16, 48)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_2 (AveragePo  (None, 16, 16, 288)  0          ['mixed1[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 16, 16, 64)   76800       ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 16, 16, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 16, 16, 64)  192         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 16, 16, 64)  192         ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 16, 16, 96)  288         ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 16, 16, 64)  192         ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " mixed2 (Concatenate)           (None, 16, 16, 288)  0           ['activation_19[0][0]',          \n",
            "                                                                  'activation_21[0][0]',          \n",
            "                                                                  'activation_24[0][0]',          \n",
            "                                                                  'activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 16, 16, 64)  192         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 16, 16, 96)  288         ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 7, 7, 384)    995328      ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 7, 7, 96)     82944       ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 7, 7, 384)   1152        ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 7, 7, 96)    288         ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 7, 7, 384)    0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 7, 7, 96)     0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)   0           ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed3 (Concatenate)           (None, 7, 7, 768)    0           ['activation_26[0][0]',          \n",
            "                                                                  'activation_29[0][0]',          \n",
            "                                                                  'max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 7, 7, 128)   384         ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_34[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 7, 7, 128)   384         ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_35[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 7, 7, 128)   384         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 7, 7, 128)   384         ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_36[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 7, 7, 128)   384         ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 7, 7, 128)   384         ['conv2d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_3 (AveragePo  (None, 7, 7, 768)   0           ['mixed3[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 7, 7, 192)    172032      ['activation_32[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 7, 7, 192)    172032      ['activation_37[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_3[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 7, 7, 192)   576         ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 7, 7, 192)   576         ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 7, 7, 192)   576         ['conv2d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 7, 7, 192)   576         ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " mixed4 (Concatenate)           (None, 7, 7, 768)    0           ['activation_30[0][0]',          \n",
            "                                                                  'activation_33[0][0]',          \n",
            "                                                                  'activation_38[0][0]',          \n",
            "                                                                  'activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 7, 7, 160)   480         ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_44[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 7, 7, 160)   480         ['conv2d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_45 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_45[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 7, 7, 160)   480         ['conv2d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 7, 7, 160)   480         ['conv2d_46[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " activation_46 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_46[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 7, 7, 160)   480         ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 7, 7, 160)   480         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " activation_47 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_4 (AveragePo  (None, 7, 7, 768)   0           ['mixed4[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_47[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_4[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 7, 7, 192)   576         ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 7, 7, 192)   576         ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 7, 7, 192)   576         ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 7, 7, 192)   576         ['conv2d_49[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " activation_48 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " activation_49 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " mixed5 (Concatenate)           (None, 7, 7, 768)    0           ['activation_40[0][0]',          \n",
            "                                                                  'activation_43[0][0]',          \n",
            "                                                                  'activation_48[0][0]',          \n",
            "                                                                  'activation_49[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 7, 7, 160)   480         ['conv2d_54[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_54 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_54[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 7, 7, 160)   480         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_55 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_55[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_55[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 7, 7, 160)   480         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 7, 7, 160)   480         ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_51 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " activation_56 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_51[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_56[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 7, 7, 160)   480         ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 7, 7, 160)   480         ['conv2d_57[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_52 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_52[0][0]'] \n",
            "                                                                                                  \n",
            " activation_57 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_5 (AveragePo  (None, 7, 7, 768)   0           ['mixed5[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_52[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_57[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_5[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 7, 7, 192)   576         ['conv2d_50[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 7, 7, 192)   576         ['conv2d_53[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 7, 7, 192)   576         ['conv2d_58[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 7, 7, 192)   576         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_50 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " activation_53 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_53[0][0]'] \n",
            "                                                                                                  \n",
            " activation_58 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_58[0][0]'] \n",
            "                                                                                                  \n",
            " activation_59 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_59[0][0]'] \n",
            "                                                                                                  \n",
            " mixed6 (Concatenate)           (None, 7, 7, 768)    0           ['activation_50[0][0]',          \n",
            "                                                                  'activation_53[0][0]',          \n",
            "                                                                  'activation_58[0][0]',          \n",
            "                                                                  'activation_59[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 7, 7, 192)   576         ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_64 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_64[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_64[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 7, 7, 192)   576         ['conv2d_65[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_65 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_65[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_65[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 7, 7, 192)   576         ['conv2d_61[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 7, 7, 192)   576         ['conv2d_66[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_61 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_61[0][0]'] \n",
            "                                                                                                  \n",
            " activation_66 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_61[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_66[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 7, 7, 192)   576         ['conv2d_62[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, 7, 7, 192)   576         ['conv2d_67[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_62 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " activation_67 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_67[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_6 (AveragePo  (None, 7, 7, 768)   0           ['mixed6[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_62[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_67[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_6[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 7, 7, 192)   576         ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 7, 7, 192)   576         ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, 7, 7, 192)   576         ['conv2d_68[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, 7, 7, 192)   576         ['conv2d_69[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_60 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " activation_63 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " activation_68 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_68[0][0]'] \n",
            "                                                                                                  \n",
            " activation_69 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_69[0][0]'] \n",
            "                                                                                                  \n",
            " mixed7 (Concatenate)           (None, 7, 7, 768)    0           ['activation_60[0][0]',          \n",
            "                                                                  'activation_63[0][0]',          \n",
            "                                                                  'activation_68[0][0]',          \n",
            "                                                                  'activation_69[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_72 (BatchN  (None, 7, 7, 192)   576         ['conv2d_72[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_72 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_72[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_72[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_73 (BatchN  (None, 7, 7, 192)   576         ['conv2d_73[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_73 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_73[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_73[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_70 (BatchN  (None, 7, 7, 192)   576         ['conv2d_70[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_74 (BatchN  (None, 7, 7, 192)   576         ['conv2d_74[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_70 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_70[0][0]'] \n",
            "                                                                                                  \n",
            " activation_74 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_74[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)             (None, 3, 3, 320)    552960      ['activation_70[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)             (None, 3, 3, 192)    331776      ['activation_74[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_71 (BatchN  (None, 3, 3, 320)   960         ['conv2d_71[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_75 (BatchN  (None, 3, 3, 192)   576         ['conv2d_75[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_71 (Activation)     (None, 3, 3, 320)    0           ['batch_normalization_71[0][0]'] \n",
            "                                                                                                  \n",
            " activation_75 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_75[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)   0           ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed8 (Concatenate)           (None, 3, 3, 1280)   0           ['activation_71[0][0]',          \n",
            "                                                                  'activation_75[0][0]',          \n",
            "                                                                  'max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)             (None, 3, 3, 448)    573440      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_80 (BatchN  (None, 3, 3, 448)   1344        ['conv2d_80[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_80 (Activation)     (None, 3, 3, 448)    0           ['batch_normalization_80[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)             (None, 3, 3, 384)    491520      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)             (None, 3, 3, 384)    1548288     ['activation_80[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_77 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_77[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_81 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_81[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_77 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_77[0][0]'] \n",
            "                                                                                                  \n",
            " activation_81 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_81[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_77[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_77[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_81[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_81[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d_7 (AveragePo  (None, 3, 3, 1280)  0           ['mixed8[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)             (None, 3, 3, 320)    409600      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_78 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_78[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_79 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_79[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_82 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_82[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_83 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_83[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)             (None, 3, 3, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_76 (BatchN  (None, 3, 3, 320)   960         ['conv2d_76[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_78 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_78[0][0]'] \n",
            "                                                                                                  \n",
            " activation_79 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_79[0][0]'] \n",
            "                                                                                                  \n",
            " activation_82 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_82[0][0]'] \n",
            "                                                                                                  \n",
            " activation_83 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_83[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_84 (BatchN  (None, 3, 3, 192)   576         ['conv2d_84[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_76 (Activation)     (None, 3, 3, 320)    0           ['batch_normalization_76[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9_0 (Concatenate)         (None, 3, 3, 768)    0           ['activation_78[0][0]',          \n",
            "                                                                  'activation_79[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 3, 3, 768)    0           ['activation_82[0][0]',          \n",
            "                                                                  'activation_83[0][0]']          \n",
            "                                                                                                  \n",
            " activation_84 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_84[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9 (Concatenate)           (None, 3, 3, 2048)   0           ['activation_76[0][0]',          \n",
            "                                                                  'mixed9_0[0][0]',               \n",
            "                                                                  'concatenate[0][0]',            \n",
            "                                                                  'activation_84[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)             (None, 3, 3, 448)    917504      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_89 (BatchN  (None, 3, 3, 448)   1344        ['conv2d_89[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_89 (Activation)     (None, 3, 3, 448)    0           ['batch_normalization_89[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)             (None, 3, 3, 384)    786432      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)             (None, 3, 3, 384)    1548288     ['activation_89[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_86 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_86[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_90 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_90[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_86 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_86[0][0]'] \n",
            "                                                                                                  \n",
            " activation_90 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_90[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_86[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_86[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_90[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_90[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d_8 (AveragePo  (None, 3, 3, 2048)  0           ['mixed9[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)             (None, 3, 3, 320)    655360      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_87 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_87[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_88 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_88[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_91 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_91[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_92 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_92[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)             (None, 3, 3, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_85 (BatchN  (None, 3, 3, 320)   960         ['conv2d_85[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_87 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_87[0][0]'] \n",
            "                                                                                                  \n",
            " activation_88 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_88[0][0]'] \n",
            "                                                                                                  \n",
            " activation_91 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_91[0][0]'] \n",
            "                                                                                                  \n",
            " activation_92 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_92[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_93 (BatchN  (None, 3, 3, 192)   576         ['conv2d_93[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_85 (Activation)     (None, 3, 3, 320)    0           ['batch_normalization_85[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9_1 (Concatenate)         (None, 3, 3, 768)    0           ['activation_87[0][0]',          \n",
            "                                                                  'activation_88[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 3, 3, 768)    0           ['activation_91[0][0]',          \n",
            "                                                                  'activation_92[0][0]']          \n",
            "                                                                                                  \n",
            " activation_93 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_93[0][0]'] \n",
            "                                                                                                  \n",
            " mixed10 (Concatenate)          (None, 3, 3, 2048)   0           ['activation_85[0][0]',          \n",
            "                                                                  'mixed9_1[0][0]',               \n",
            "                                                                  'concatenate_1[0][0]',          \n",
            "                                                                  'activation_93[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFOolSfx2YA7",
        "outputId": "021ebc2e-7d84-4625-9554-1c0369308243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "last layer output shape:  (None, 7, 7, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation = 'relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation = 'sigmoid')(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LI7q9esY2f1T",
        "outputId": "8188d5c4-4946-4723-85e0-41c95c3501f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 74, 74, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 74, 74, 32)  96          ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 74, 74, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 72, 72, 32)   9216        ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 72, 72, 32)  96          ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 72, 72, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 72, 72, 64)   18432       ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 72, 72, 64)  192         ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 72, 72, 64)   0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 35, 35, 64)   0           ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 35, 35, 80)   5120        ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 35, 35, 80)  240         ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 35, 35, 80)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 33, 33, 192)  138240      ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 33, 33, 192)  576        ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 33, 33, 192)  0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0          ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 16, 16, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 16, 16, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 16, 16, 96)   55296       ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 16, 16, 48)  144         ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 16, 16, 96)  288         ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 16, 16, 48)   0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 16, 16, 96)   0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 16, 16, 192)  0          ['max_pooling2d_1[0][0]']        \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 16, 16, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 16, 16, 64)   76800       ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 16, 16, 32)   6144        ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 16, 16, 96)  288         ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 16, 16, 32)  96          ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 16, 16, 32)   0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " mixed0 (Concatenate)           (None, 16, 16, 256)  0           ['activation_5[0][0]',           \n",
            "                                                                  'activation_7[0][0]',           \n",
            "                                                                  'activation_10[0][0]',          \n",
            "                                                                  'activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 16, 16, 64)  192         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 16, 16, 48)   12288       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 16, 16, 48)  144         ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 16, 16, 96)  288         ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 16, 16, 48)   0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (AveragePo  (None, 16, 16, 256)  0          ['mixed0[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 16, 16, 64)   76800       ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 16, 16, 64)   16384       ['average_pooling2d_1[0][0]']    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 16, 16, 64)  192         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 16, 16, 64)  192         ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 16, 16, 96)  288         ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 16, 16, 64)  192         ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " mixed1 (Concatenate)           (None, 16, 16, 288)  0           ['activation_12[0][0]',          \n",
            "                                                                  'activation_14[0][0]',          \n",
            "                                                                  'activation_17[0][0]',          \n",
            "                                                                  'activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 16, 16, 64)  192         ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 16, 16, 48)   13824       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 16, 16, 48)  144         ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 16, 16, 96)  288         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 16, 16, 48)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_2 (AveragePo  (None, 16, 16, 288)  0          ['mixed1[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 16, 16, 64)   76800       ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 16, 16, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 16, 16, 64)  192         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 16, 16, 64)  192         ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 16, 16, 96)  288         ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 16, 16, 64)  192         ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " mixed2 (Concatenate)           (None, 16, 16, 288)  0           ['activation_19[0][0]',          \n",
            "                                                                  'activation_21[0][0]',          \n",
            "                                                                  'activation_24[0][0]',          \n",
            "                                                                  'activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 16, 16, 64)  192         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 16, 16, 96)  288         ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 7, 7, 384)    995328      ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 7, 7, 96)     82944       ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 7, 7, 384)   1152        ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 7, 7, 96)    288         ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 7, 7, 384)    0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 7, 7, 96)     0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)   0           ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed3 (Concatenate)           (None, 7, 7, 768)    0           ['activation_26[0][0]',          \n",
            "                                                                  'activation_29[0][0]',          \n",
            "                                                                  'max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 7, 7, 128)   384         ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_34[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 7, 7, 128)   384         ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_35[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 7, 7, 128)   384         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 7, 7, 128)   384         ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_36[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 7, 7, 128)   384         ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 7, 7, 128)   384         ['conv2d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_3 (AveragePo  (None, 7, 7, 768)   0           ['mixed3[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 7, 7, 192)    172032      ['activation_32[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 7, 7, 192)    172032      ['activation_37[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_3[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 7, 7, 192)   576         ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 7, 7, 192)   576         ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 7, 7, 192)   576         ['conv2d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 7, 7, 192)   576         ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " mixed4 (Concatenate)           (None, 7, 7, 768)    0           ['activation_30[0][0]',          \n",
            "                                                                  'activation_33[0][0]',          \n",
            "                                                                  'activation_38[0][0]',          \n",
            "                                                                  'activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 7, 7, 160)   480         ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_44[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 7, 7, 160)   480         ['conv2d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_45 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_45[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 7, 7, 160)   480         ['conv2d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 7, 7, 160)   480         ['conv2d_46[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " activation_46 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_46[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 7, 7, 160)   480         ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 7, 7, 160)   480         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " activation_47 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_4 (AveragePo  (None, 7, 7, 768)   0           ['mixed4[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_47[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_4[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 7, 7, 192)   576         ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 7, 7, 192)   576         ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 7, 7, 192)   576         ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 7, 7, 192)   576         ['conv2d_49[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " activation_48 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " activation_49 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " mixed5 (Concatenate)           (None, 7, 7, 768)    0           ['activation_40[0][0]',          \n",
            "                                                                  'activation_43[0][0]',          \n",
            "                                                                  'activation_48[0][0]',          \n",
            "                                                                  'activation_49[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 7, 7, 160)   480         ['conv2d_54[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_54 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_54[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 7, 7, 160)   480         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_55 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_55[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_55[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 7, 7, 160)   480         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 7, 7, 160)   480         ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_51 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " activation_56 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_51[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_56[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 7, 7, 160)   480         ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 7, 7, 160)   480         ['conv2d_57[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_52 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_52[0][0]'] \n",
            "                                                                                                  \n",
            " activation_57 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_5 (AveragePo  (None, 7, 7, 768)   0           ['mixed5[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_52[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_57[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_5[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 7, 7, 192)   576         ['conv2d_50[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 7, 7, 192)   576         ['conv2d_53[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 7, 7, 192)   576         ['conv2d_58[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 7, 7, 192)   576         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_50 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " activation_53 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_53[0][0]'] \n",
            "                                                                                                  \n",
            " activation_58 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_58[0][0]'] \n",
            "                                                                                                  \n",
            " activation_59 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_59[0][0]'] \n",
            "                                                                                                  \n",
            " mixed6 (Concatenate)           (None, 7, 7, 768)    0           ['activation_50[0][0]',          \n",
            "                                                                  'activation_53[0][0]',          \n",
            "                                                                  'activation_58[0][0]',          \n",
            "                                                                  'activation_59[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 7, 7, 192)   576         ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_64 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_64[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_64[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 7, 7, 192)   576         ['conv2d_65[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_65 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_65[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_65[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 7, 7, 192)   576         ['conv2d_61[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 7, 7, 192)   576         ['conv2d_66[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_61 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_61[0][0]'] \n",
            "                                                                                                  \n",
            " activation_66 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_61[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_66[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 7, 7, 192)   576         ['conv2d_62[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, 7, 7, 192)   576         ['conv2d_67[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_62 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " activation_67 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_67[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_6 (AveragePo  (None, 7, 7, 768)   0           ['mixed6[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_62[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_67[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_6[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 7, 7, 192)   576         ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 7, 7, 192)   576         ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, 7, 7, 192)   576         ['conv2d_68[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, 7, 7, 192)   576         ['conv2d_69[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_60 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " activation_63 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " activation_68 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_68[0][0]'] \n",
            "                                                                                                  \n",
            " activation_69 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_69[0][0]'] \n",
            "                                                                                                  \n",
            " mixed7 (Concatenate)           (None, 7, 7, 768)    0           ['activation_60[0][0]',          \n",
            "                                                                  'activation_63[0][0]',          \n",
            "                                                                  'activation_68[0][0]',          \n",
            "                                                                  'activation_69[0][0]']          \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 37632)        0           ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1024)         38536192    ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 1024)         0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 1)            1025        ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting the dataset from the drive\n",
        "path_dataset = f\"{getcwd()}/../content/drive/MyDrive/CNNRelatedFolders/Datasets/meat_quality_assessment_dataset.zip\"\n"
      ],
      "metadata": {
        "id": "wIcJ0TJ92kwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Below is the part where most of the code will be changed to match the custom dataset**\n",
        "\n",
        "Changes include:\n",
        "*   Apple -> Spoiled\n",
        "*   Banana -> Fresh\n",
        "*   Name of the path folders as well as other texts to follow the changes above"
      ],
      "metadata": {
        "id": "3sqmV-aL21sz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Code below is for deleting folders**\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# import shutil\n",
        "\n",
        "shutil.rmtree('/folder_name')  # change to folder name\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "9PxPPjLq6Zzk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Added path to the `zip.extractall()` as an argument to extract files in that specific folder**\n",
        "Note: you have to create the folder first; I am unsure if this will still work if the folder does not exist:\n",
        "\n",
        "Confirmed: You skip creating the folder first before running.\n",
        "\n",
        "Folder name: MQA; abbrev. for Meat Quality Assessment\n",
        "\n",
        "Delete any other unnecessary files like .txt files."
      ],
      "metadata": {
        "id": "FXx4sVba_8RH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#UnZipping the File\n",
        "from zipfile import ZipFile\n",
        "file_name = path_dataset\n",
        "\n",
        "with ZipFile(file_name,'r') as zip:\n",
        "  zip.extractall('../content/MQA')  # added a path to extract all of the files in the dataset zip\n",
        "  print('Done')\n",
        "\n",
        "#Defining dataset path and finding number of files\n",
        "import os \n",
        "Spoiled = os.path.join('../content/MQA/Spoiled')\n",
        "Fresh = os.path.join('../content/MQA/Fresh')\n",
        "print('Total Spoiled Images:',len(os.listdir(Spoiled)))\n",
        "print('Total Fresh Images:',len(os.listdir(Fresh)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iTpGm_i2w9t",
        "outputId": "8ca0ea1b-8b99-4125-9b70-444ee4728916"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n",
            "Total Spoiled Images: 948\n",
            "Total Fresh Images: 948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *I am unsure if the code below is needed... Regardless, here it is*"
      ],
      "metadata": {
        "id": "GrL6lX6RBHr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#List of Spoiled and Fresh Images\n",
        "Spoiled_files = os.listdir(Spoiled)\n",
        "print(Spoiled_files[:10])\n",
        "Fresh_files = os.listdir(Fresh)\n",
        "print(Fresh_files[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWvEw3SIAwG_",
        "outputId": "69936b19-ecde-4b73-cbcc-7b20a538d4f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['test_20171019_002321D.jpg', 'test_20171018_084321D.jpg', 'test_20171019_015321D.jpg', 'test_20171018_081721D.jpg', 'test_20171018_203721D.jpg', 'test_20171018_172321D.jpg', 'test_20171018_203121D.jpg', 'test_20171018_031921D.jpg', 'test_20171018_034121D.jpg', 'test_20171018_213121D.jpg']\n",
            "['test_20171016_195121D.jpg', 'test_20171017_162121D.jpg', 'test_20171017_152721D.jpg', 'test_20171016_232921D.jpg', 'test_20171016_181521D.jpg', 'test_20171016_203921D.jpg', 'test_20171017_010521D.jpg', 'test_20171017_051521D.jpg', 'test_20171016_203521D.jpg', 'test_20171017_153121D.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *The code below makes two copies (test and train) of the original dataset for training and testing*\n",
        "The no. of images in both folders are equal to the original since it is yet to be divided."
      ],
      "metadata": {
        "id": "cdn1yVK2CGtH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Train-Test Partitioning\n",
        "from glob import glob\n",
        "import os.path\n",
        "from shutil import copy2\n",
        "\n",
        "path = '../content/MQA'  # the path of the dataset\n",
        "test = '../content/Test'  # new folder for the test dataset\n",
        "train = '../content/Train'  # new folder for the training dataset\n",
        "\n",
        "if not os.path.exists(test):\n",
        "\tos.makedirs(test)\n",
        "if not os.path.exists(train):\n",
        "\tos.makedirs(train)\n",
        " \n",
        "for folder in glob(path+'/*'):\n",
        "\t\tprint(folder)\n",
        "\t\t# find number of images in folder\n",
        "\t\tno_images_in_folder = len(os.listdir(folder))\n",
        "\t\t# make new folder inside test and train\n",
        "\t\tfolder_test = test+'/'+folder.split('/')[3]+'/'\n",
        "\t\tfolder_train = train+'/'+folder.split('/')[3]+'/'\n",
        "\t\t# print(folder_test)\n",
        "\t\t# print(folder_train)\n",
        "\t\tif not os.path.exists(folder_test):\n",
        "\t\t\tos.makedirs(folder_test)\n",
        "\t\tif not os.path.exists(folder_train):\n",
        "\t\t\tos.makedirs(folder_train)\n",
        "\n",
        "\t\tprint(\"no of images in this folder: {}\".format(no_images_in_folder))\n",
        "\t\ttrain_num = int(no_images_in_folder*0.8)\n",
        "\t\t\n",
        "\t\t# iterate from 0..test and copy to test\n",
        "\t\t# iterate test to end and copy to train\n",
        "\t\tfor idx, im in enumerate(glob(folder+'/*')):\n",
        "\t\t\t#print(im)\n",
        "\t\t\tif idx <= train_num:\n",
        "\t\t\t# copy to test\n",
        "\t\t\t\tcopy2(im, folder_train)\n",
        "\t\t\telse:\n",
        "\t\t\t# copy to train\n",
        "\t\t\t\tcopy2(im, folder_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPnZyMhBBYoY",
        "outputId": "a1dead7e-b38d-43d4-9251-b9c3067454fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "../content/MQA/Spoiled\n",
            "no of images in this folder: 948\n",
            "../content/MQA/Fresh\n",
            "no of images in this folder: 948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *This divides the dataset into 80% for training and 20% for testing*"
      ],
      "metadata": {
        "id": "Hw4KKEiOEZYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/content/Train'\n",
        "validation_dir = '/content/Test'\n",
        "\n",
        "train_spoiled_dir = os.path.join(train_dir,'Spoiled')\n",
        "train_fresh_dir = os.path.join(train_dir,'Fresh')\n",
        "validation_spoiled_dir = os.path.join(validation_dir,'Spoiled')\n",
        "validation_fresh_dir = os.path.join(validation_dir,'Fresh')\n",
        "\n",
        "train_spoiled_fnames = os.listdir(train_spoiled_dir)\n",
        "train_fresh_fnames = os.listdir(train_fresh_dir)\n",
        "validation_spoiled_fnames = os.listdir(validation_spoiled_dir)\n",
        "validation_fresh_fnames = os.listdir(validation_fresh_dir)\n",
        "\n",
        "print(len(train_spoiled_fnames))\n",
        "print(len(train_fresh_fnames))\n",
        "print(len(validation_spoiled_fnames))\n",
        "print(len(validation_fresh_fnames))\n",
        "\n",
        "#Expected Output: depends on the dataset size\n",
        "#759\n",
        "#759\n",
        "#189\n",
        "#189"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHecH3vHCrav",
        "outputId": "4b277568-5fd7-430d-fc95-404d279072cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "759\n",
            "759\n",
            "189\n",
            "189\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Change the code below and try to get a higher accuracy. It might be because the images are bad. Try to optimize this and use other datasets.***"
      ],
      "metadata": {
        "id": "9NovJjUZKJwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,  # This is the source directory for training images\n",
        "        target_size=(150,150), \n",
        "        batch_size=20,\n",
        "        class_mode='binary')\n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir,  # This is the source directory for training images\n",
        "        target_size=(150,150), \n",
        "        batch_size=20,\n",
        "        class_mode='binary')\n",
        "\n",
        "# Expected Output: not accurate\n",
        "# Found 787 images belonging to 2 classes.\n",
        "# Found 195 images belonging to 2 classes."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_7bi51eGZCs",
        "outputId": "f5895aba-9f70-452a-86c9-d6e33b3bf988"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1518 images belonging to 2 classes.\n",
            "Found 378 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.0%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "      def on_epoch_end(self, epoch, logs={}):\n",
        "        if(logs.get('acc')>0.99):\n",
        "            print(\"\\nReached 99.0% accuracy so cancelling training!\")\n",
        "            self.model.stop_training = True "
      ],
      "metadata": {
        "id": "isv8QSseHDsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99% accuracy\n",
        "\n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator(train_generator,\n",
        "                             validation_data = validation_generator,\n",
        "                             steps_per_epoch = 10,\n",
        "                             epochs = 100,\n",
        "                             validation_steps = 10,\n",
        "                             verbose = 1,\n",
        "                             callbacks=[callbacks])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pj5C0hxEHQz1",
        "outputId": "029bf306-04d6-4336-8260-33e04a6d7a66"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 27s 2s/step - loss: 0.6923 - acc: 0.5100 - val_loss: 0.6910 - val_acc: 0.5150\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 22s 2s/step - loss: 0.6814 - acc: 0.5850 - val_loss: 0.6995 - val_acc: 0.4800\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6920 - acc: 0.5200 - val_loss: 0.6976 - val_acc: 0.4700\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6934 - acc: 0.5050 - val_loss: 0.6854 - val_acc: 0.5450\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6944 - acc: 0.4650 - val_loss: 0.6924 - val_acc: 0.4550\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6887 - acc: 0.5202 - val_loss: 0.6881 - val_acc: 0.5150\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6911 - acc: 0.4850 - val_loss: 0.6906 - val_acc: 0.4750\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6880 - acc: 0.5100 - val_loss: 0.6886 - val_acc: 0.4850\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6826 - acc: 0.5450 - val_loss: 0.6867 - val_acc: 0.5100\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6790 - acc: 0.5600 - val_loss: 0.6863 - val_acc: 0.5150\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6940 - acc: 0.4550 - val_loss: 0.6893 - val_acc: 0.4550\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6876 - acc: 0.4899 - val_loss: 0.6861 - val_acc: 0.4750\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6874 - acc: 0.5100 - val_loss: 0.6831 - val_acc: 0.5200\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6863 - acc: 0.4900 - val_loss: 0.6856 - val_acc: 0.4650\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6857 - acc: 0.4899 - val_loss: 0.6838 - val_acc: 0.4700\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 22s 2s/step - loss: 0.6837 - acc: 0.5150 - val_loss: 0.6847 - val_acc: 0.9750\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6779 - acc: 0.6000 - val_loss: 0.6781 - val_acc: 0.5300\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6829 - acc: 0.5200 - val_loss: 0.6790 - val_acc: 0.5100\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6801 - acc: 0.5400 - val_loss: 0.6794 - val_acc: 0.4950\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 22s 2s/step - loss: 0.6834 - acc: 0.4950 - val_loss: 0.6790 - val_acc: 0.5050\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6775 - acc: 0.5500 - val_loss: 0.6792 - val_acc: 0.4900\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6809 - acc: 0.5000 - val_loss: 0.6759 - val_acc: 0.5300\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6795 - acc: 0.5100 - val_loss: 0.6764 - val_acc: 0.5100\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6772 - acc: 0.5300 - val_loss: 0.6743 - val_acc: 0.5050\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6814 - acc: 0.4850 - val_loss: 0.6752 - val_acc: 0.7450\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6779 - acc: 0.5250 - val_loss: 0.6769 - val_acc: 0.9550\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6742 - acc: 0.6100 - val_loss: 0.6756 - val_acc: 0.9650\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6702 - acc: 0.5500 - val_loss: 0.6722 - val_acc: 0.8700\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6777 - acc: 0.5200 - val_loss: 0.6801 - val_acc: 0.7900\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6683 - acc: 0.5850 - val_loss: 0.6719 - val_acc: 0.9100\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6721 - acc: 0.5150 - val_loss: 0.6755 - val_acc: 0.8850\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6711 - acc: 0.7000 - val_loss: 0.6630 - val_acc: 0.5350\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6665 - acc: 0.5500 - val_loss: 0.6650 - val_acc: 0.9250\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6676 - acc: 0.5650 - val_loss: 0.6621 - val_acc: 0.5600\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6746 - acc: 0.5700 - val_loss: 0.6718 - val_acc: 0.8600\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6678 - acc: 0.5900 - val_loss: 0.6665 - val_acc: 0.9700\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6654 - acc: 0.6350 - val_loss: 0.6598 - val_acc: 0.8150\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6651 - acc: 0.5350 - val_loss: 0.6653 - val_acc: 0.9450\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6621 - acc: 0.5758 - val_loss: 0.6608 - val_acc: 0.8900\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6650 - acc: 0.6600 - val_loss: 0.6567 - val_acc: 0.9500\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6685 - acc: 0.5950 - val_loss: 0.6643 - val_acc: 0.9450\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6643 - acc: 0.6000 - val_loss: 0.6669 - val_acc: 0.8300\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6590 - acc: 0.6850 - val_loss: 0.6618 - val_acc: 0.8750\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6507 - acc: 0.6550 - val_loss: 0.6515 - val_acc: 0.8500\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 22s 2s/step - loss: 0.6595 - acc: 0.6100 - val_loss: 0.6541 - val_acc: 0.9750\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6583 - acc: 0.6250 - val_loss: 0.6515 - val_acc: 0.9600\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6533 - acc: 0.6100 - val_loss: 0.6609 - val_acc: 0.8500\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6523 - acc: 0.7100 - val_loss: 0.6489 - val_acc: 0.9750\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6492 - acc: 0.6250 - val_loss: 0.6485 - val_acc: 0.9050\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6547 - acc: 0.6400 - val_loss: 0.6440 - val_acc: 0.8950\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6536 - acc: 0.5750 - val_loss: 0.6557 - val_acc: 0.8550\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6588 - acc: 0.6650 - val_loss: 0.6757 - val_acc: 0.7350\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6598 - acc: 0.7525 - val_loss: 0.6594 - val_acc: 0.8100\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6518 - acc: 0.6900 - val_loss: 0.6567 - val_acc: 0.8100\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6475 - acc: 0.6950 - val_loss: 0.6534 - val_acc: 0.8050\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6584 - acc: 0.7200 - val_loss: 0.6552 - val_acc: 0.7800\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6514 - acc: 0.7475 - val_loss: 0.6684 - val_acc: 0.7250\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 23s 2s/step - loss: 0.6538 - acc: 0.7400 - val_loss: 0.6518 - val_acc: 0.7750\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6583 - acc: 0.7450 - val_loss: 0.6509 - val_acc: 0.7700\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6397 - acc: 0.7450 - val_loss: 0.6344 - val_acc: 0.9550\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6459 - acc: 0.6400 - val_loss: 0.6543 - val_acc: 0.7900\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6457 - acc: 0.7150 - val_loss: 0.6504 - val_acc: 0.7900\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6361 - acc: 0.7950 - val_loss: 0.6468 - val_acc: 0.7800\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6361 - acc: 0.7500 - val_loss: 0.6430 - val_acc: 0.7800\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6490 - acc: 0.7400 - val_loss: 0.6654 - val_acc: 0.7200\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6404 - acc: 0.7300 - val_loss: 0.6373 - val_acc: 0.8200\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6479 - acc: 0.7300 - val_loss: 0.6400 - val_acc: 0.7850\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 22s 2s/step - loss: 0.6377 - acc: 0.7700 - val_loss: 0.6568 - val_acc: 0.7400\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6316 - acc: 0.8050 - val_loss: 0.6469 - val_acc: 0.7750\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6246 - acc: 0.8450 - val_loss: 0.6497 - val_acc: 0.7500\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6349 - acc: 0.8100 - val_loss: 0.6357 - val_acc: 0.8100\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6302 - acc: 0.7850 - val_loss: 0.6403 - val_acc: 0.7800\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6294 - acc: 0.7550 - val_loss: 0.6365 - val_acc: 0.7750\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6361 - acc: 0.7450 - val_loss: 0.6580 - val_acc: 0.7000\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6316 - acc: 0.7475 - val_loss: 0.6317 - val_acc: 0.7900\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6280 - acc: 0.7250 - val_loss: 0.6377 - val_acc: 0.7700\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6313 - acc: 0.7850 - val_loss: 0.6523 - val_acc: 0.7350\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6178 - acc: 0.8200 - val_loss: 0.6325 - val_acc: 0.7700\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6237 - acc: 0.7850 - val_loss: 0.6563 - val_acc: 0.6850\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6160 - acc: 0.8250 - val_loss: 0.6119 - val_acc: 0.8400\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6253 - acc: 0.7374 - val_loss: 0.6245 - val_acc: 0.7900\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6085 - acc: 0.8200 - val_loss: 0.6236 - val_acc: 0.7600\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6023 - acc: 0.7700 - val_loss: 0.6139 - val_acc: 0.7850\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6004 - acc: 0.8350 - val_loss: 0.6042 - val_acc: 0.8600\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6139 - acc: 0.7475 - val_loss: 0.6300 - val_acc: 0.7550\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6091 - acc: 0.8200 - val_loss: 0.6185 - val_acc: 0.7600\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6106 - acc: 0.7929 - val_loss: 0.6605 - val_acc: 0.6450\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.5951 - acc: 0.8450 - val_loss: 0.5988 - val_acc: 0.8450\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6236 - acc: 0.7200 - val_loss: 0.6442 - val_acc: 0.6950\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6094 - acc: 0.8050 - val_loss: 0.6234 - val_acc: 0.7500\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6036 - acc: 0.7929 - val_loss: 0.6395 - val_acc: 0.7250\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6053 - acc: 0.8150 - val_loss: 0.6210 - val_acc: 0.7650\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.5899 - acc: 0.8232 - val_loss: 0.5947 - val_acc: 0.8000\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.5973 - acc: 0.7550 - val_loss: 0.6052 - val_acc: 0.8050\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 22s 2s/step - loss: 0.5922 - acc: 0.8150 - val_loss: 0.5927 - val_acc: 0.8150\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6052 - acc: 0.7250 - val_loss: 0.6120 - val_acc: 0.7700\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 22s 2s/step - loss: 0.5782 - acc: 0.8400 - val_loss: 0.6016 - val_acc: 0.7900\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.5848 - acc: 0.7800 - val_loss: 0.6028 - val_acc: 0.7800\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.6009 - acc: 0.7500 - val_loss: 0.5944 - val_acc: 0.7800\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.5966 - acc: 0.7700 - val_loss: 0.6165 - val_acc: 0.7300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "atJIEChXHzdD",
        "outputId": "9b1034d6-f47f-4999-b502-9534c6f21c18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion: The dataset might not be good or the optimization of the neural network.**\n",
        "\n",
        "**Advice: Try a different dataset with multiple classes instead of binary to simulate the final dataset. Last test would be the dataset with the three different kinds of meat. Fine tune that dataset and imitate the code and if possible add more into the dataset different kinds of pictures of the different cuts of specific meat.**"
      ],
      "metadata": {
        "id": "cUfMQvGcH1lm"
      }
    }
  ]
}